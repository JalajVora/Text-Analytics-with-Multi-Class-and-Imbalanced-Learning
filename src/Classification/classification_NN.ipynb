{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corpus import load_meta_data\n",
    "from features import load_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_Name</th>\n",
       "      <th>guten_genre</th>\n",
       "      <th>Author_Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pg10067</th>\n",
       "      <td>The Mystery of the Boule Cabinet: A Detective ...</td>\n",
       "      <td>Detective and Mystery</td>\n",
       "      <td>Stevenson| Burton Egbert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pg1032</th>\n",
       "      <td>The Pupil</td>\n",
       "      <td>Literary</td>\n",
       "      <td>James| Henry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pg10379</th>\n",
       "      <td>At Love's Cost</td>\n",
       "      <td>Literary</td>\n",
       "      <td>Garvice| Charles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pg10473</th>\n",
       "      <td>The Heart of the Range</td>\n",
       "      <td>Western Stories</td>\n",
       "      <td>White| William Patterson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pg10812</th>\n",
       "      <td>The Worshipper of the Image</td>\n",
       "      <td>Literary</td>\n",
       "      <td>Gallienne| Richard Le</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pg766DickensDavidCopfld</th>\n",
       "      <td>David Copperfield</td>\n",
       "      <td>Literary</td>\n",
       "      <td>Dickens| Charles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pg786DickensHardTimes</th>\n",
       "      <td>Hard Times</td>\n",
       "      <td>Literary</td>\n",
       "      <td>Dickens| Charles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pg834DoyleMemoirsSherlk</th>\n",
       "      <td>Memoirs of Shelock Holmes</td>\n",
       "      <td>Detective and Mystery</td>\n",
       "      <td>Connan| Doyle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pg863Agatha1</th>\n",
       "      <td>The Mysterious Affair at Styles</td>\n",
       "      <td>Detective and Mystery</td>\n",
       "      <td>Christie| Agatha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pg98DickensTaleCities</th>\n",
       "      <td>A Tale of Two Cities</td>\n",
       "      <td>Literary</td>\n",
       "      <td>Dickens| Charles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>996 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 Book_Name  \\\n",
       "book_id                                                                      \n",
       "pg10067                  The Mystery of the Boule Cabinet: A Detective ...   \n",
       "pg1032                                                           The Pupil   \n",
       "pg10379                                                     At Love's Cost   \n",
       "pg10473                                             The Heart of the Range   \n",
       "pg10812                                        The Worshipper of the Image   \n",
       "...                                                                    ...   \n",
       "pg766DickensDavidCopfld                                  David Copperfield   \n",
       "pg786DickensHardTimes                                           Hard Times   \n",
       "pg834DoyleMemoirsSherlk                          Memoirs of Shelock Holmes   \n",
       "pg863Agatha1                               The Mysterious Affair at Styles   \n",
       "pg98DickensTaleCities                                 A Tale of Two Cities   \n",
       "\n",
       "                                   guten_genre               Author_Name  \n",
       "book_id                                                                   \n",
       "pg10067                  Detective and Mystery  Stevenson| Burton Egbert  \n",
       "pg1032                                Literary              James| Henry  \n",
       "pg10379                               Literary          Garvice| Charles  \n",
       "pg10473                        Western Stories  White| William Patterson  \n",
       "pg10812                               Literary     Gallienne| Richard Le  \n",
       "...                                        ...                       ...  \n",
       "pg766DickensDavidCopfld               Literary          Dickens| Charles  \n",
       "pg786DickensHardTimes                 Literary          Dickens| Charles  \n",
       "pg834DoyleMemoirsSherlk  Detective and Mystery             Connan| Doyle  \n",
       "pg863Agatha1             Detective and Mystery          Christie| Agatha  \n",
       "pg98DickensTaleCities                 Literary          Dickens| Charles  \n",
       "\n",
       "[996 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data = load_meta_data()\n",
    "meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>title_avg_word_length</th>\n",
       "      <th>._count</th>\n",
       "      <th>!_count</th>\n",
       "      <th>?_count</th>\n",
       "      <th>,_count</th>\n",
       "      <th>``_count</th>\n",
       "      <th>length</th>\n",
       "      <th>proper_names</th>\n",
       "      <th>pos_sentiment</th>\n",
       "      <th>neu_sentiment</th>\n",
       "      <th>neg_sentiment</th>\n",
       "      <th>point_of_view</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pg10067</td>\n",
       "      <td>9</td>\n",
       "      <td>4.777778</td>\n",
       "      <td>0.047124</td>\n",
       "      <td>0.003927</td>\n",
       "      <td>0.007425</td>\n",
       "      <td>0.065670</td>\n",
       "      <td>0.028751</td>\n",
       "      <td>86326</td>\n",
       "      <td>0.002919</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.644986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pg1032</td>\n",
       "      <td>2</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.034161</td>\n",
       "      <td>0.003822</td>\n",
       "      <td>0.005542</td>\n",
       "      <td>0.045963</td>\n",
       "      <td>0.016149</td>\n",
       "      <td>20930</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.272887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pg10379</td>\n",
       "      <td>3</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.036540</td>\n",
       "      <td>0.006190</td>\n",
       "      <td>0.005673</td>\n",
       "      <td>0.064081</td>\n",
       "      <td>0.017677</td>\n",
       "      <td>183689</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.456420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pg10473</td>\n",
       "      <td>5</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.063323</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>0.009745</td>\n",
       "      <td>0.050225</td>\n",
       "      <td>0.031861</td>\n",
       "      <td>115440</td>\n",
       "      <td>0.003067</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.575733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pg10812</td>\n",
       "      <td>5</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.040540</td>\n",
       "      <td>0.005314</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>0.067206</td>\n",
       "      <td>0.016131</td>\n",
       "      <td>21263</td>\n",
       "      <td>0.003715</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.318627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>pg766DickensDavidCopfld</td>\n",
       "      <td>2</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.034839</td>\n",
       "      <td>0.006531</td>\n",
       "      <td>0.004193</td>\n",
       "      <td>0.084033</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>429805</td>\n",
       "      <td>0.003455</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.708288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>pg786DickensHardTimes</td>\n",
       "      <td>2</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.038167</td>\n",
       "      <td>0.005037</td>\n",
       "      <td>0.004909</td>\n",
       "      <td>0.082862</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>125474</td>\n",
       "      <td>0.006607</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.522765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>pg834DoyleMemoirsSherlk</td>\n",
       "      <td>4</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.045144</td>\n",
       "      <td>0.002106</td>\n",
       "      <td>0.005615</td>\n",
       "      <td>0.058558</td>\n",
       "      <td>0.021029</td>\n",
       "      <td>104000</td>\n",
       "      <td>0.005471</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.649575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>pg863Agatha1</td>\n",
       "      <td>5</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>0.056792</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>0.011474</td>\n",
       "      <td>0.058872</td>\n",
       "      <td>0.030001</td>\n",
       "      <td>72598</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.669434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>pg98DickensTaleCities</td>\n",
       "      <td>5</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>0.035153</td>\n",
       "      <td>0.005978</td>\n",
       "      <td>0.005029</td>\n",
       "      <td>0.078704</td>\n",
       "      <td>0.013378</td>\n",
       "      <td>21079</td>\n",
       "      <td>0.008350</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.467312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>996 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     book_id  title_word_count  title_avg_word_length  \\\n",
       "0                    pg10067                 9               4.777778   \n",
       "1                     pg1032                 2               4.000000   \n",
       "2                    pg10379                 3               4.000000   \n",
       "3                    pg10473                 5               3.600000   \n",
       "4                    pg10812                 5               4.600000   \n",
       "..                       ...               ...                    ...   \n",
       "991  pg766DickensDavidCopfld                 2               8.000000   \n",
       "992    pg786DickensHardTimes                 2               4.500000   \n",
       "993  pg834DoyleMemoirsSherlk                 4               5.500000   \n",
       "994             pg863Agatha1                 5               5.400000   \n",
       "995    pg98DickensTaleCities                 5               3.200000   \n",
       "\n",
       "      ._count   !_count   ?_count   ,_count  ``_count  length  proper_names  \\\n",
       "0    0.047124  0.003927  0.007425  0.065670  0.028751   86326      0.002919   \n",
       "1    0.034161  0.003822  0.005542  0.045963  0.016149   20930      0.004157   \n",
       "2    0.036540  0.006190  0.005673  0.064081  0.017677  183689      0.002433   \n",
       "3    0.063323  0.003170  0.009745  0.050225  0.031861  115440      0.003067   \n",
       "4    0.040540  0.005314  0.004233  0.067206  0.016131   21263      0.003715   \n",
       "..        ...       ...       ...       ...       ...     ...           ...   \n",
       "991  0.034839  0.006531  0.004193  0.084033  0.000412  429805      0.003455   \n",
       "992  0.038167  0.005037  0.004909  0.082862  0.000215  125474      0.006607   \n",
       "993  0.045144  0.002106  0.005615  0.058558  0.021029  104000      0.005471   \n",
       "994  0.056792  0.005689  0.011474  0.058872  0.030001   72598      0.003223   \n",
       "995  0.035153  0.005978  0.005029  0.078704  0.013378   21079      0.008350   \n",
       "\n",
       "     pos_sentiment  neu_sentiment  neg_sentiment  point_of_view  \n",
       "0            0.104          0.800          0.096       0.644986  \n",
       "1            0.143          0.779          0.078       0.272887  \n",
       "2            0.156          0.759          0.085       0.456420  \n",
       "3            0.100          0.824          0.076       0.575733  \n",
       "4            0.163          0.715          0.122       0.318627  \n",
       "..             ...            ...            ...            ...  \n",
       "991          0.138          0.779          0.083       0.708288  \n",
       "992          0.122          0.794          0.083       0.522765  \n",
       "993          0.099          0.817          0.084       0.649575  \n",
       "994          0.112          0.784          0.105       0.669434  \n",
       "995          0.099          0.813          0.089       0.467312  \n",
       "\n",
       "[996 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = load_features()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = meta_data.guten_genre\n",
    "num_genre = labels.nunique()\n",
    "num_features = features.shape[1]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>title_avg_word_length</th>\n",
       "      <th>._count</th>\n",
       "      <th>!_count</th>\n",
       "      <th>?_count</th>\n",
       "      <th>,_count</th>\n",
       "      <th>``_count</th>\n",
       "      <th>length</th>\n",
       "      <th>proper_names</th>\n",
       "      <th>pos_sentiment</th>\n",
       "      <th>neu_sentiment</th>\n",
       "      <th>neg_sentiment</th>\n",
       "      <th>point_of_view</th>\n",
       "      <th>guten_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pg10067</td>\n",
       "      <td>9</td>\n",
       "      <td>4.777778</td>\n",
       "      <td>0.047124</td>\n",
       "      <td>0.003927</td>\n",
       "      <td>0.007425</td>\n",
       "      <td>0.065670</td>\n",
       "      <td>0.028751</td>\n",
       "      <td>86326</td>\n",
       "      <td>0.002919</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.644986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pg1032</td>\n",
       "      <td>2</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.034161</td>\n",
       "      <td>0.003822</td>\n",
       "      <td>0.005542</td>\n",
       "      <td>0.045963</td>\n",
       "      <td>0.016149</td>\n",
       "      <td>20930</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.272887</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pg10379</td>\n",
       "      <td>3</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.036540</td>\n",
       "      <td>0.006190</td>\n",
       "      <td>0.005673</td>\n",
       "      <td>0.064081</td>\n",
       "      <td>0.017677</td>\n",
       "      <td>183689</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.456420</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pg10473</td>\n",
       "      <td>5</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.063323</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>0.009745</td>\n",
       "      <td>0.050225</td>\n",
       "      <td>0.031861</td>\n",
       "      <td>115440</td>\n",
       "      <td>0.003067</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.575733</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pg10812</td>\n",
       "      <td>5</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.040540</td>\n",
       "      <td>0.005314</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>0.067206</td>\n",
       "      <td>0.016131</td>\n",
       "      <td>21263</td>\n",
       "      <td>0.003715</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.318627</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7141</th>\n",
       "      <td>pg35078</td>\n",
       "      <td>3</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.053052</td>\n",
       "      <td>0.007277</td>\n",
       "      <td>0.005576</td>\n",
       "      <td>0.060283</td>\n",
       "      <td>0.015442</td>\n",
       "      <td>65275</td>\n",
       "      <td>0.003845</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.466785</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7142</th>\n",
       "      <td>pg35078</td>\n",
       "      <td>3</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.053052</td>\n",
       "      <td>0.007277</td>\n",
       "      <td>0.005576</td>\n",
       "      <td>0.060283</td>\n",
       "      <td>0.015442</td>\n",
       "      <td>65275</td>\n",
       "      <td>0.003845</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.466785</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7143</th>\n",
       "      <td>pg45618</td>\n",
       "      <td>9</td>\n",
       "      <td>5.111111</td>\n",
       "      <td>0.050923</td>\n",
       "      <td>0.007559</td>\n",
       "      <td>0.007261</td>\n",
       "      <td>0.062262</td>\n",
       "      <td>0.031661</td>\n",
       "      <td>30163</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.619808</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7144</th>\n",
       "      <td>pg46457</td>\n",
       "      <td>6</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.055904</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.048150</td>\n",
       "      <td>0.018912</td>\n",
       "      <td>78152</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.345463</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7145</th>\n",
       "      <td>pg42423</td>\n",
       "      <td>3</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.045495</td>\n",
       "      <td>0.003727</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>0.056152</td>\n",
       "      <td>0.012957</td>\n",
       "      <td>91768</td>\n",
       "      <td>0.002953</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.447735</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7146 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      book_id  title_word_count  title_avg_word_length   ._count   !_count  \\\n",
       "0     pg10067                 9               4.777778  0.047124  0.003927   \n",
       "1      pg1032                 2               4.000000  0.034161  0.003822   \n",
       "2     pg10379                 3               4.000000  0.036540  0.006190   \n",
       "3     pg10473                 5               3.600000  0.063323  0.003170   \n",
       "4     pg10812                 5               4.600000  0.040540  0.005314   \n",
       "...       ...               ...                    ...       ...       ...   \n",
       "7141  pg35078                 3               4.000000  0.053052  0.007277   \n",
       "7142  pg35078                 3               4.000000  0.053052  0.007277   \n",
       "7143  pg45618                 9               5.111111  0.050923  0.007559   \n",
       "7144  pg46457                 6               4.666667  0.055904  0.004171   \n",
       "7145  pg42423                 3               7.333333  0.045495  0.003727   \n",
       "\n",
       "       ?_count   ,_count  ``_count  length  proper_names  pos_sentiment  \\\n",
       "0     0.007425  0.065670  0.028751   86326      0.002919          0.104   \n",
       "1     0.005542  0.045963  0.016149   20930      0.004157          0.143   \n",
       "2     0.005673  0.064081  0.017677  183689      0.002433          0.156   \n",
       "3     0.009745  0.050225  0.031861  115440      0.003067          0.100   \n",
       "4     0.004233  0.067206  0.016131   21263      0.003715          0.163   \n",
       "...        ...       ...       ...     ...           ...            ...   \n",
       "7141  0.005576  0.060283  0.015442   65275      0.003845          0.102   \n",
       "7142  0.005576  0.060283  0.015442   65275      0.003845          0.102   \n",
       "7143  0.007261  0.062262  0.031661   30163      0.002254          0.112   \n",
       "7144  0.005323  0.048150  0.018912   78152      0.003954          0.090   \n",
       "7145  0.002746  0.056152  0.012957   91768      0.002953          0.130   \n",
       "\n",
       "      neu_sentiment  neg_sentiment  point_of_view  guten_genre  \n",
       "0             0.800          0.096       0.644986            0  \n",
       "1             0.779          0.078       0.272887            1  \n",
       "2             0.759          0.085       0.456420            1  \n",
       "3             0.824          0.076       0.575733            2  \n",
       "4             0.715          0.122       0.318627            1  \n",
       "...             ...            ...            ...          ...  \n",
       "7141          0.799          0.099       0.466785            2  \n",
       "7142          0.799          0.099       0.466785            2  \n",
       "7143          0.758          0.130       0.619808            2  \n",
       "7144          0.808          0.102       0.345463            2  \n",
       "7145          0.786          0.083       0.447735            2  \n",
       "\n",
       "[7146 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imblearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "int_labels = pd.factorize(meta_data.guten_genre)\n",
    "features['guten_genre'] = int_labels[0]\n",
    "overSampler = imblearn.over_sampling.RandomOverSampler()\n",
    "sampled_features_and_labels = overSampler.fit_resample(features, labels.to_numpy())\n",
    "sampled_features_and_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>title_avg_word_length</th>\n",
       "      <th>._count</th>\n",
       "      <th>!_count</th>\n",
       "      <th>?_count</th>\n",
       "      <th>,_count</th>\n",
       "      <th>``_count</th>\n",
       "      <th>length</th>\n",
       "      <th>proper_names</th>\n",
       "      <th>pos_sentiment</th>\n",
       "      <th>neu_sentiment</th>\n",
       "      <th>neg_sentiment</th>\n",
       "      <th>point_of_view</th>\n",
       "      <th>guten_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pg10067</td>\n",
       "      <td>1.069037</td>\n",
       "      <td>-0.193615</td>\n",
       "      <td>0.429930</td>\n",
       "      <td>-0.152337</td>\n",
       "      <td>1.294345</td>\n",
       "      <td>0.199349</td>\n",
       "      <td>1.744788</td>\n",
       "      <td>0.120565</td>\n",
       "      <td>-0.595611</td>\n",
       "      <td>-1.264918</td>\n",
       "      <td>0.928045</td>\n",
       "      <td>0.045119</td>\n",
       "      <td>0.950449</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pg1032</td>\n",
       "      <td>-0.960465</td>\n",
       "      <td>-0.825904</td>\n",
       "      <td>-0.904736</td>\n",
       "      <td>-0.187713</td>\n",
       "      <td>0.365802</td>\n",
       "      <td>-1.534659</td>\n",
       "      <td>0.137312</td>\n",
       "      <td>-1.250344</td>\n",
       "      <td>-0.190432</td>\n",
       "      <td>0.364152</td>\n",
       "      <td>0.265870</td>\n",
       "      <td>-0.869150</td>\n",
       "      <td>-1.374870</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pg10379</td>\n",
       "      <td>-0.670537</td>\n",
       "      <td>-0.825904</td>\n",
       "      <td>-0.659829</td>\n",
       "      <td>0.612160</td>\n",
       "      <td>0.430077</td>\n",
       "      <td>0.059575</td>\n",
       "      <td>0.332156</td>\n",
       "      <td>2.161604</td>\n",
       "      <td>-0.754634</td>\n",
       "      <td>0.907175</td>\n",
       "      <td>-0.364774</td>\n",
       "      <td>-0.513601</td>\n",
       "      <td>-0.227937</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pg10473</td>\n",
       "      <td>-0.090679</td>\n",
       "      <td>-1.151081</td>\n",
       "      <td>2.097901</td>\n",
       "      <td>-0.407919</td>\n",
       "      <td>2.438336</td>\n",
       "      <td>-1.159603</td>\n",
       "      <td>2.141379</td>\n",
       "      <td>0.730887</td>\n",
       "      <td>-0.547364</td>\n",
       "      <td>-1.432002</td>\n",
       "      <td>1.684818</td>\n",
       "      <td>-0.970735</td>\n",
       "      <td>0.517673</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pg10812</td>\n",
       "      <td>-0.090679</td>\n",
       "      <td>-0.338138</td>\n",
       "      <td>-0.247977</td>\n",
       "      <td>0.316402</td>\n",
       "      <td>-0.279956</td>\n",
       "      <td>0.334526</td>\n",
       "      <td>0.135047</td>\n",
       "      <td>-1.243364</td>\n",
       "      <td>-0.334929</td>\n",
       "      <td>1.199572</td>\n",
       "      <td>-1.752190</td>\n",
       "      <td>1.365730</td>\n",
       "      <td>-1.089030</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7141</th>\n",
       "      <td>pg35078</td>\n",
       "      <td>-0.670537</td>\n",
       "      <td>-0.825904</td>\n",
       "      <td>1.040392</td>\n",
       "      <td>0.979435</td>\n",
       "      <td>0.382629</td>\n",
       "      <td>-0.274586</td>\n",
       "      <td>0.047170</td>\n",
       "      <td>-0.320732</td>\n",
       "      <td>-0.292400</td>\n",
       "      <td>-1.348460</td>\n",
       "      <td>0.896513</td>\n",
       "      <td>0.197497</td>\n",
       "      <td>-0.163162</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7142</th>\n",
       "      <td>pg35078</td>\n",
       "      <td>-0.670537</td>\n",
       "      <td>-0.825904</td>\n",
       "      <td>1.040392</td>\n",
       "      <td>0.979435</td>\n",
       "      <td>0.382629</td>\n",
       "      <td>-0.274586</td>\n",
       "      <td>0.047170</td>\n",
       "      <td>-0.320732</td>\n",
       "      <td>-0.292400</td>\n",
       "      <td>-1.348460</td>\n",
       "      <td>0.896513</td>\n",
       "      <td>0.197497</td>\n",
       "      <td>-0.163162</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7143</th>\n",
       "      <td>pg45618</td>\n",
       "      <td>1.069037</td>\n",
       "      <td>0.077366</td>\n",
       "      <td>0.821161</td>\n",
       "      <td>1.074717</td>\n",
       "      <td>1.213086</td>\n",
       "      <td>-0.100516</td>\n",
       "      <td>2.115945</td>\n",
       "      <td>-1.056791</td>\n",
       "      <td>-0.813253</td>\n",
       "      <td>-0.930750</td>\n",
       "      <td>-0.396306</td>\n",
       "      <td>1.772072</td>\n",
       "      <td>0.793110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7144</th>\n",
       "      <td>pg46457</td>\n",
       "      <td>0.199250</td>\n",
       "      <td>-0.283942</td>\n",
       "      <td>1.333990</td>\n",
       "      <td>-0.069772</td>\n",
       "      <td>0.257653</td>\n",
       "      <td>-1.342223</td>\n",
       "      <td>0.489715</td>\n",
       "      <td>-0.050789</td>\n",
       "      <td>-0.256856</td>\n",
       "      <td>-1.849712</td>\n",
       "      <td>1.180303</td>\n",
       "      <td>0.349875</td>\n",
       "      <td>-0.921328</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7145</th>\n",
       "      <td>pg42423</td>\n",
       "      <td>-0.670537</td>\n",
       "      <td>1.883906</td>\n",
       "      <td>0.262246</td>\n",
       "      <td>-0.219970</td>\n",
       "      <td>-1.013029</td>\n",
       "      <td>-0.638066</td>\n",
       "      <td>-0.269898</td>\n",
       "      <td>0.234646</td>\n",
       "      <td>-0.584501</td>\n",
       "      <td>-0.178872</td>\n",
       "      <td>0.486595</td>\n",
       "      <td>-0.615186</td>\n",
       "      <td>-0.282213</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7146 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      book_id  title_word_count  title_avg_word_length   ._count   !_count  \\\n",
       "0     pg10067          1.069037              -0.193615  0.429930 -0.152337   \n",
       "1      pg1032         -0.960465              -0.825904 -0.904736 -0.187713   \n",
       "2     pg10379         -0.670537              -0.825904 -0.659829  0.612160   \n",
       "3     pg10473         -0.090679              -1.151081  2.097901 -0.407919   \n",
       "4     pg10812         -0.090679              -0.338138 -0.247977  0.316402   \n",
       "...       ...               ...                    ...       ...       ...   \n",
       "7141  pg35078         -0.670537              -0.825904  1.040392  0.979435   \n",
       "7142  pg35078         -0.670537              -0.825904  1.040392  0.979435   \n",
       "7143  pg45618          1.069037               0.077366  0.821161  1.074717   \n",
       "7144  pg46457          0.199250              -0.283942  1.333990 -0.069772   \n",
       "7145  pg42423         -0.670537               1.883906  0.262246 -0.219970   \n",
       "\n",
       "       ?_count   ,_count  ``_count    length  proper_names  pos_sentiment  \\\n",
       "0     1.294345  0.199349  1.744788  0.120565     -0.595611      -1.264918   \n",
       "1     0.365802 -1.534659  0.137312 -1.250344     -0.190432       0.364152   \n",
       "2     0.430077  0.059575  0.332156  2.161604     -0.754634       0.907175   \n",
       "3     2.438336 -1.159603  2.141379  0.730887     -0.547364      -1.432002   \n",
       "4    -0.279956  0.334526  0.135047 -1.243364     -0.334929       1.199572   \n",
       "...        ...       ...       ...       ...           ...            ...   \n",
       "7141  0.382629 -0.274586  0.047170 -0.320732     -0.292400      -1.348460   \n",
       "7142  0.382629 -0.274586  0.047170 -0.320732     -0.292400      -1.348460   \n",
       "7143  1.213086 -0.100516  2.115945 -1.056791     -0.813253      -0.930750   \n",
       "7144  0.257653 -1.342223  0.489715 -0.050789     -0.256856      -1.849712   \n",
       "7145 -1.013029 -0.638066 -0.269898  0.234646     -0.584501      -0.178872   \n",
       "\n",
       "      neu_sentiment  neg_sentiment  point_of_view  guten_genre  \n",
       "0          0.928045       0.045119       0.950449            0  \n",
       "1          0.265870      -0.869150      -1.374870            1  \n",
       "2         -0.364774      -0.513601      -0.227937            1  \n",
       "3          1.684818      -0.970735       0.517673            2  \n",
       "4         -1.752190       1.365730      -1.089030            1  \n",
       "...             ...            ...            ...          ...  \n",
       "7141       0.896513       0.197497      -0.163162            2  \n",
       "7142       0.896513       0.197497      -0.163162            2  \n",
       "7143      -0.396306       1.772072       0.793110            2  \n",
       "7144       1.180303       0.349875      -0.921328            2  \n",
       "7145       0.486595      -0.615186      -0.282213            2  \n",
       "\n",
       "[7146 rows x 15 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_features = sampled_features_and_labels[0]\n",
    "scalable_axes = scaled_features.axes[1][1:-1]\n",
    "scaled_features[scalable_axes] = scaler.fit_transform(sampled_features_and_labels[0][scalable_axes])\n",
    "scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>title_avg_word_length</th>\n",
       "      <th>._count</th>\n",
       "      <th>!_count</th>\n",
       "      <th>?_count</th>\n",
       "      <th>,_count</th>\n",
       "      <th>``_count</th>\n",
       "      <th>length</th>\n",
       "      <th>proper_names</th>\n",
       "      <th>pos_sentiment</th>\n",
       "      <th>neu_sentiment</th>\n",
       "      <th>neg_sentiment</th>\n",
       "      <th>point_of_view</th>\n",
       "      <th>guten_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pg33498</td>\n",
       "      <td>3.388467</td>\n",
       "      <td>0.417421</td>\n",
       "      <td>0.630661</td>\n",
       "      <td>2.213394</td>\n",
       "      <td>1.070078</td>\n",
       "      <td>-0.577969</td>\n",
       "      <td>0.433896</td>\n",
       "      <td>-0.338781</td>\n",
       "      <td>2.215013</td>\n",
       "      <td>-0.011788</td>\n",
       "      <td>0.108209</td>\n",
       "      <td>-0.158052</td>\n",
       "      <td>0.102124</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pg1392</td>\n",
       "      <td>-0.380608</td>\n",
       "      <td>0.393511</td>\n",
       "      <td>-1.225256</td>\n",
       "      <td>-0.234995</td>\n",
       "      <td>-0.964028</td>\n",
       "      <td>1.563953</td>\n",
       "      <td>-0.577527</td>\n",
       "      <td>-1.438615</td>\n",
       "      <td>3.024475</td>\n",
       "      <td>0.614778</td>\n",
       "      <td>0.076677</td>\n",
       "      <td>-0.869150</td>\n",
       "      <td>0.563653</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pg34619</td>\n",
       "      <td>-0.670537</td>\n",
       "      <td>0.799982</td>\n",
       "      <td>-0.176423</td>\n",
       "      <td>-0.965047</td>\n",
       "      <td>-1.065445</td>\n",
       "      <td>1.169554</td>\n",
       "      <td>-0.756508</td>\n",
       "      <td>-0.077014</td>\n",
       "      <td>-0.248570</td>\n",
       "      <td>1.199572</td>\n",
       "      <td>-0.711628</td>\n",
       "      <td>-0.310430</td>\n",
       "      <td>-0.163684</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pg34035</td>\n",
       "      <td>-0.960465</td>\n",
       "      <td>-0.012961</td>\n",
       "      <td>1.266331</td>\n",
       "      <td>0.480083</td>\n",
       "      <td>1.351075</td>\n",
       "      <td>-0.376239</td>\n",
       "      <td>1.644615</td>\n",
       "      <td>0.573915</td>\n",
       "      <td>-0.723386</td>\n",
       "      <td>-0.262414</td>\n",
       "      <td>0.991110</td>\n",
       "      <td>-1.275492</td>\n",
       "      <td>0.295065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pg13057</td>\n",
       "      <td>-0.960465</td>\n",
       "      <td>2.019397</td>\n",
       "      <td>1.294039</td>\n",
       "      <td>-0.534331</td>\n",
       "      <td>0.675390</td>\n",
       "      <td>-0.645941</td>\n",
       "      <td>-1.901227</td>\n",
       "      <td>-0.309705</td>\n",
       "      <td>0.443889</td>\n",
       "      <td>-1.306689</td>\n",
       "      <td>1.432560</td>\n",
       "      <td>-0.716772</td>\n",
       "      <td>-1.190759</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7141</th>\n",
       "      <td>pg6410</td>\n",
       "      <td>1.648894</td>\n",
       "      <td>-0.456384</td>\n",
       "      <td>1.557202</td>\n",
       "      <td>1.141163</td>\n",
       "      <td>0.708881</td>\n",
       "      <td>-1.525358</td>\n",
       "      <td>0.956685</td>\n",
       "      <td>1.059821</td>\n",
       "      <td>-0.355404</td>\n",
       "      <td>-0.095330</td>\n",
       "      <td>-0.364774</td>\n",
       "      <td>0.705424</td>\n",
       "      <td>0.148969</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7142</th>\n",
       "      <td>pg42115</td>\n",
       "      <td>0.779108</td>\n",
       "      <td>-0.724286</td>\n",
       "      <td>-0.135022</td>\n",
       "      <td>-0.085646</td>\n",
       "      <td>0.240347</td>\n",
       "      <td>0.507829</td>\n",
       "      <td>0.935047</td>\n",
       "      <td>0.923434</td>\n",
       "      <td>-0.726445</td>\n",
       "      <td>-0.011788</td>\n",
       "      <td>-0.144049</td>\n",
       "      <td>0.248290</td>\n",
       "      <td>0.012043</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7143</th>\n",
       "      <td>pg8182</td>\n",
       "      <td>-0.090679</td>\n",
       "      <td>-0.988493</td>\n",
       "      <td>-0.823650</td>\n",
       "      <td>-0.615494</td>\n",
       "      <td>0.130146</td>\n",
       "      <td>0.142601</td>\n",
       "      <td>0.067181</td>\n",
       "      <td>-0.811564</td>\n",
       "      <td>-0.855270</td>\n",
       "      <td>-1.264918</td>\n",
       "      <td>1.117239</td>\n",
       "      <td>-0.259637</td>\n",
       "      <td>-0.370366</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7144</th>\n",
       "      <td>pg525</td>\n",
       "      <td>-0.670537</td>\n",
       "      <td>0.258020</td>\n",
       "      <td>0.476614</td>\n",
       "      <td>-0.097049</td>\n",
       "      <td>-0.939632</td>\n",
       "      <td>0.379365</td>\n",
       "      <td>-0.999416</td>\n",
       "      <td>-1.355999</td>\n",
       "      <td>1.621729</td>\n",
       "      <td>-1.181376</td>\n",
       "      <td>0.770385</td>\n",
       "      <td>0.197497</td>\n",
       "      <td>1.501381</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7145</th>\n",
       "      <td>pg37430</td>\n",
       "      <td>1.069037</td>\n",
       "      <td>0.077366</td>\n",
       "      <td>1.046096</td>\n",
       "      <td>-0.315139</td>\n",
       "      <td>1.604701</td>\n",
       "      <td>0.177420</td>\n",
       "      <td>1.560417</td>\n",
       "      <td>0.039018</td>\n",
       "      <td>2.114452</td>\n",
       "      <td>-1.014292</td>\n",
       "      <td>1.243367</td>\n",
       "      <td>-0.767564</td>\n",
       "      <td>-0.564947</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7146 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      book_id  title_word_count  title_avg_word_length   ._count   !_count  \\\n",
       "0     pg33498          3.388467               0.417421  0.630661  2.213394   \n",
       "1      pg1392         -0.380608               0.393511 -1.225256 -0.234995   \n",
       "2     pg34619         -0.670537               0.799982 -0.176423 -0.965047   \n",
       "3     pg34035         -0.960465              -0.012961  1.266331  0.480083   \n",
       "4     pg13057         -0.960465               2.019397  1.294039 -0.534331   \n",
       "...       ...               ...                    ...       ...       ...   \n",
       "7141   pg6410          1.648894              -0.456384  1.557202  1.141163   \n",
       "7142  pg42115          0.779108              -0.724286 -0.135022 -0.085646   \n",
       "7143   pg8182         -0.090679              -0.988493 -0.823650 -0.615494   \n",
       "7144    pg525         -0.670537               0.258020  0.476614 -0.097049   \n",
       "7145  pg37430          1.069037               0.077366  1.046096 -0.315139   \n",
       "\n",
       "       ?_count   ,_count  ``_count    length  proper_names  pos_sentiment  \\\n",
       "0     1.070078 -0.577969  0.433896 -0.338781      2.215013      -0.011788   \n",
       "1    -0.964028  1.563953 -0.577527 -1.438615      3.024475       0.614778   \n",
       "2    -1.065445  1.169554 -0.756508 -0.077014     -0.248570       1.199572   \n",
       "3     1.351075 -0.376239  1.644615  0.573915     -0.723386      -0.262414   \n",
       "4     0.675390 -0.645941 -1.901227 -0.309705      0.443889      -1.306689   \n",
       "...        ...       ...       ...       ...           ...            ...   \n",
       "7141  0.708881 -1.525358  0.956685  1.059821     -0.355404      -0.095330   \n",
       "7142  0.240347  0.507829  0.935047  0.923434     -0.726445      -0.011788   \n",
       "7143  0.130146  0.142601  0.067181 -0.811564     -0.855270      -1.264918   \n",
       "7144 -0.939632  0.379365 -0.999416 -1.355999      1.621729      -1.181376   \n",
       "7145  1.604701  0.177420  1.560417  0.039018      2.114452      -1.014292   \n",
       "\n",
       "      neu_sentiment  neg_sentiment  point_of_view  guten_genre  \n",
       "0          0.108209      -0.158052       0.102124            2  \n",
       "1          0.076677      -0.869150       0.563653            4  \n",
       "2         -0.711628      -0.310430      -0.163684            3  \n",
       "3          0.991110      -1.275492       0.295065            0  \n",
       "4          1.432560      -0.716772      -1.190759            1  \n",
       "...             ...            ...            ...          ...  \n",
       "7141      -0.364774       0.705424       0.148969            8  \n",
       "7142      -0.144049       0.248290       0.012043            2  \n",
       "7143       1.117239      -0.259637      -0.370366            3  \n",
       "7144       0.770385       0.197497       1.501381            6  \n",
       "7145       1.243367      -0.767564      -0.564947            8  \n",
       "\n",
       "[7146 rows x 15 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_features = scaled_features.sample(frac=1).reset_index(drop=True) #shuffle\n",
    "scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7146, 15) (2372, 15) (4774, 15)\n"
     ]
    }
   ],
   "source": [
    "mask = msk = np.random.rand(len(scaled_features)) < 0.666\n",
    "test_features = scaled_features[~msk]\n",
    "train_features = scaled_features[msk]\n",
    "print(scaled_features.shape, test_features.shape, train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------ a NN\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 1\n",
    "w_range = 0.1\n",
    "learning_rate=0.005\n",
    "layer_list = [\n",
    "    Dense(128, input_dim = num_features, kernel_initializer=tf.initializers.RandomUniform(minval=-w_range, maxval=w_range)),\n",
    "    Dense(64, activation='relu', kernel_initializer=tf.initializers.RandomUniform(minval=-w_range, maxval=w_range)),\n",
    "    Dense(32, activation='relu', kernel_initializer=tf.initializers.RandomUniform(minval=-w_range, maxval=w_range)),\n",
    "    Dense(num_genre)]\n",
    "layer_list2 = [\n",
    "    keras.Input(shape=(num_features)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(num_genre)]\n",
    "\n",
    "opt = tf.optimizers.SGD(learning_rate=learning_rate)\n",
    "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(layer_list)\n",
    "model2 = tf.keras.Sequential(layer_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_199 (Dense)            (None, 128)               1792      \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 9)                 297       \n",
      "=================================================================\n",
      "Total params: 12,425\n",
      "Trainable params: 12,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tensorboard visualization:\n",
    "import os\n",
    "import datetime\n",
    "from time import time\n",
    "logdir = os.path.join(\"logs\", \"idl21\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "train_writer = tf.summary.create_file_writer(os.path.join(logdir, \"train\"))\n",
    "test_writer = tf.summary.create_file_writer(os.path.join(logdir, \"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.3884675   0.41742078  0.63066057 ...  0.10820871 -0.15805182\n",
      "   0.10212437]\n",
      " [-0.3806077   0.39351069 -1.22525583 ...  0.07667653 -0.86914994\n",
      "   0.5636526 ]\n",
      " [-0.67053657  0.79998222 -0.17642264 ... -0.71162807 -0.31042999\n",
      "  -0.16368444]\n",
      " ...\n",
      " [-0.67053657 -0.55492288  0.26156251 ... -2.19364072  3.19426787\n",
      "  -1.20376893]\n",
      " [ 0.77910774 -0.72428601 -0.13502246 ... -0.14404876  0.24828996\n",
      "   0.01204322]\n",
      " [-0.09067884 -0.98849251 -0.82364995 ...  1.1172386  -0.25963727\n",
      "  -0.37036627]]\n",
      "[2 4 3 ... 7 2 3]\n",
      "Train on 4774 samples\n",
      "4774/4774 [==============================] - 3s 536us/sample - loss: 2.0946 - accuracy: 0.2468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2776d453dc8>"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_test = pd.DataFrame(data = train_features)\n",
    "train_labels_test = train_features['guten_genre']\n",
    "train_features_test = train_features_test.drop('book_id', axis=1)\n",
    "train_features_test = train_features_test.drop('guten_genre', axis=1)\n",
    "model2.compile(loss=loss_fn, optimizer=opt, metrics=['accuracy'])\n",
    "print(train_features_test.to_numpy())\n",
    "print(train_labels_test.to_numpy())\n",
    "model2.fit(train_features_test.to_numpy(), train_labels_test.to_numpy(), epochs=1, batch_size=batch_size, verbose=1, class_weight=w_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 2.1856489181518555 Accuracy: 0.125 OutExample: [3 3 4 5 1 6 2 2] LabelExample: [2 4 3 0 7 6 6 8]\n",
      "Epoch: 0 Loss: 2.153493642807007 Accuracy: 0.20499999821186066 OutExample: [3 3 5 7 7 3 0 2] LabelExample: [3 6 2 0 7 5 7 4]\n",
      "Epoch: 0 Loss: 2.1980180740356445 Accuracy: 0.11749999970197678 OutExample: [7 7 7 7 7 7 7 7] LabelExample: [5 3 0 3 3 5 3 4]\n",
      "Epoch: 0 Loss: 2.202533483505249 Accuracy: 0.10875000059604645 OutExample: [7 7 7 7 7 7 7 7] LabelExample: [1 5 6 3 5 1 1 1]\n",
      "Epoch: 0 Loss: 2.2008156776428223 Accuracy: 0.0949999988079071 OutExample: [1 1 1 1 1 1 1 1] LabelExample: [8 4 1 4 4 8 5 3]\n",
      "Epoch: 0 Loss: 2.19093656539917 Accuracy: 0.11500000208616257 OutExample: [7 7 7 7 7 7 7 7] LabelExample: [7 7 1 1 5 0 2 6]\n"
     ]
    }
   ],
   "source": [
    "#input_ in sampled_features_and_labels[0].iterrows(): \n",
    "#input_ in enumerate(sampled_features_and_labels[0]):\n",
    "input_length = len(train_features)\n",
    "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for step, input_ in train_features.groupby(np.arange(input_length) // batch_size):\n",
    "        #if step > train_steps:\n",
    "        #    break\n",
    "        dataFrame = pd.DataFrame(data = input_)\n",
    "        labels_ = dataFrame.guten_genre\n",
    "        labels_ = labels_.to_numpy()\n",
    "\n",
    "        features_ = input_.drop('book_id', axis=1)\n",
    "        features_ = features_.drop('guten_genre', axis=1)\n",
    "        features_ = np.asarray(features_).astype(np.float32)\n",
    "            \n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(features_)\n",
    "            xent = loss_fn(labels_, logits)\n",
    "\n",
    "        varis = model.trainable_variables\n",
    "        grads = tape.gradient(xent, varis)\n",
    "      \n",
    "        opt.apply_gradients(zip(grads, varis))\n",
    "\n",
    "        train_acc_metric(labels_, logits)\n",
    "        \n",
    "        with train_writer.as_default():\n",
    "            tf.summary.scalar(\"loss\", xent, step=step)\n",
    "            #tf.summary.histogram((\"weights\"), varis, step=step)\n",
    "            tf.summary.histogram((\"logits\"), logits, step=step)\n",
    "            tf.summary.histogram(\"output\", np.argmax(logits, axis=-1), step=step)\n",
    "\n",
    "    \n",
    "        if not step % 100:\n",
    "            acc = train_acc_metric.result()\n",
    "            print(\"Epoch: {} Loss: {} Accuracy: {} OutExample: {} LabelExample: {}\".format(\n",
    "                epoch, xent, acc, np.argmax(logits, axis=-1), str(labels_)))\n",
    "            train_acc_metric.reset_states()\n",
    "            varstep = 0\n",
    "            with train_writer.as_default():\n",
    "                for vars in varis:                    \n",
    "                    tf.summary.histogram((\"weights\"+str(varstep)), vars, step=step)\n",
    "                    varstep = varstep + 1\n",
    "                    tf.summary.scalar(\"accuracy\", acc, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2]\n",
      "tf.Tensor(\n",
      "[[ 0.00227066 -0.00149452  0.01363323 -0.01107438 -0.01190203 -0.00367624\n",
      "   0.00198645  0.00481698  0.0008062 ]\n",
      " [ 0.00227066 -0.00149452  0.01363323 -0.01107438 -0.01190203 -0.00367624\n",
      "   0.00198645  0.00481698  0.0008062 ]\n",
      " [ 0.00227066 -0.00149452  0.01363323 -0.01107438 -0.01190203 -0.00367624\n",
      "   0.00198645  0.00481698  0.0008062 ]\n",
      " [ 0.00227066 -0.00149452  0.01363323 -0.01107438 -0.01190203 -0.00367624\n",
      "   0.00198645  0.00481698  0.0008062 ]\n",
      " [ 0.00227066 -0.00149452  0.01363323 -0.01107438 -0.01190203 -0.00367624\n",
      "   0.00198645  0.00481698  0.0008062 ]\n",
      " [ 0.00227066 -0.00149452  0.01363323 -0.01107438 -0.01190203 -0.00367624\n",
      "   0.00198645  0.00481698  0.0008062 ]\n",
      " [ 0.00227066 -0.00149452  0.01363323 -0.01107438 -0.01190203 -0.00367624\n",
      "   0.00198645  0.00481698  0.0008062 ]\n",
      " [ 0.00227066 -0.00149452  0.01363323 -0.01107438 -0.01190203 -0.00367624\n",
      "   0.00198645  0.00481698  0.0008062 ]], shape=(8, 9), dtype=float32)\n",
      "[[-0.96046543  2.0193968   1.2940385  -0.53433144  0.6753901  -0.6459409\n",
      "  -1.9012266  -0.309705    0.44388926 -1.3066889   1.4325604  -0.7167718\n",
      "  -1.1907586 ]\n",
      " [-0.09067884  1.6129253  -1.1523657  -1.31026    -1.0627841   0.3884488\n",
      "  -0.7641528  -0.2625797   0.45495716 -1.0142919   0.5181271   0.3498754\n",
      "   1.7488368 ]\n",
      " [-0.6705366  -0.01296084  0.91908497 -0.43522575 -0.34665737 -1.2151823\n",
      "   0.73970246 -0.10820675  0.70621634 -1.0560628   1.180303   -0.61518633\n",
      "  -0.60298556]\n",
      " [-0.6705366  -0.01296084 -0.43888158  2.2927501   0.07046366  1.2729926\n",
      "   0.51813066 -0.93426144  0.43081856  0.40592256 -0.2701775  -0.05646638\n",
      "  -0.21300945]\n",
      " [ 0.4891789  -1.1743081  -2.2758827  -0.6661071  -1.9256159   2.1318886\n",
      "  -1.3372478  -0.9398796  -0.67192936 -0.22064263 -0.869289    1.6704862\n",
      "  -2.3233385 ]\n",
      " [ 1.0690366   0.07736617  1.0460956  -0.31513926  1.6047007   0.17742035\n",
      "   1.5604166   0.03901777  2.1144521  -1.0142919   1.2433673  -0.7675645\n",
      "  -0.5649472 ]\n",
      " [-0.96046543  0.3935107  -0.3467388   0.18808529 -0.8741084  -0.6888941\n",
      "  -0.57673675  0.12488301 -0.72652966 -1.1813759   0.8019168   0.09591179\n",
      "  -1.8863393 ]\n",
      " [ 1.0690366  -0.8259039  -1.2583818   0.0720613  -0.61411947  0.08304343\n",
      "  -1.9065992  -0.5156474  -0.0598858  -1.682628    1.2748995  -0.00567366\n",
      "   0.97755057]]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "tf.Tensor(\n",
      "[[ 0.00227066 -0.00149452  0.01363323 -0.01107438 -0.01190203 -0.00367624\n",
      "   0.00198645  0.00481698  0.0008062 ]\n",
      " [ 0.00227066 -0.00149452  0.01363323 -0.01107438 -0.01190203 -0.00367624\n",
      "   0.00198645  0.00481698  0.0008062 ]\n",
      " [ 0.00227066 -0.00149452  0.01363323 -0.01107438 -0.01190203 -0.00367624\n",
      "   0.00198645  0.00481698  0.0008062 ]\n",
      " [ 0.00227066 -0.00149452  0.01363323 -0.01107438 -0.01190203 -0.00367624\n",
      "   0.00198645  0.00481698  0.0008062 ]\n",
      " [ 0.00227066 -0.00149452  0.01363323 -0.01107438 -0.01190203 -0.00367624\n",
      "   0.00198645  0.00481698  0.0008062 ]\n",
      " [ 0.00227066 -0.00149452  0.01363323 -0.01107438 -0.01190203 -0.00367624\n",
      "   0.00198645  0.00481698  0.0008062 ]\n",
      " [ 0.00227066 -0.00149452  0.01363323 -0.01107438 -0.01190203 -0.00367624\n",
      "   0.00198645  0.00481698  0.0008062 ]\n",
      " [ 0.00227066 -0.00149452  0.01363323 -0.01107438 -0.01190203 -0.00367624\n",
      "   0.00198645  0.00481698  0.0008062 ]], shape=(8, 9), dtype=float32)\n",
      "[[-3.8060769e-01 -8.2590389e-01  5.5483562e-01  1.0878702e+00\n",
      "   4.7737008e-01  1.3128186e+00  7.8729308e-01  1.7880034e-01\n",
      "   6.5328848e-01  1.1995718e+00 -3.6477405e-01 -8.1835723e-01\n",
      "   1.7084397e+00]\n",
      " [-6.7053658e-01  2.5802019e-01  1.3277061e+00  1.3029351e+00\n",
      "   1.4059014e+00 -2.7178252e+00  9.7533959e-01  1.3049808e-03\n",
      "  -3.5359189e-01  3.2238054e-01 -6.4856368e-01  6.5463173e-01\n",
      "   7.8001760e-02]\n",
      " [-6.7053658e-01 -5.5492288e-01  2.6156253e-01  4.3106535e-01\n",
      "   4.2078492e-01  4.6613404e-01 -1.8462735e+00 -1.4665325e-01\n",
      "  -4.0333620e-01  2.8060952e-01 -2.1936407e+00  3.1942677e+00\n",
      "  -1.2037690e+00]\n",
      " [-3.8060769e-01 -2.1619660e-01 -4.7505477e-01 -1.1969556e+00\n",
      "  -1.9740883e+00  1.6247157e+00 -1.3706447e+00 -1.1367868e+00\n",
      "  -1.4714880e-01  2.2438471e+00 -1.7521901e+00  9.5911793e-02\n",
      "   2.1492901e+00]\n",
      " [-6.7053658e-01 -1.2960837e-02 -4.3888158e-01  2.2927501e+00\n",
      "   7.0463665e-02  1.2729926e+00  5.1813066e-01 -9.3426144e-01\n",
      "   4.3081856e-01  4.0592256e-01 -2.7017751e-01 -5.6466378e-02\n",
      "  -2.1300945e-01]\n",
      " [-6.7053658e-01  1.8839062e+00  2.6224613e-01 -2.1996965e-01\n",
      "  -1.0130287e+00 -6.3806641e-01 -2.6989830e-01  2.3464631e-01\n",
      "  -5.8450133e-01 -1.7887162e-01  4.8659492e-01 -6.1518633e-01\n",
      "  -2.8221276e-01]\n",
      " [ 3.3884676e+00 -5.8680302e-01 -2.0508146e+00 -2.0472552e-01\n",
      "  -1.3386798e+00  7.8360742e-01 -7.4239439e-01 -7.4429297e-01\n",
      "  -2.5103894e-01  7.1754463e-02 -1.1846108e+00  1.8228644e+00\n",
      "  -1.3998678e+00]\n",
      " [ 4.8917890e-01  3.3544332e-01 -8.3102500e-01 -6.7967427e-01\n",
      "  -1.6826691e-01  9.1712677e-01 -4.7446886e-01 -7.6768792e-01\n",
      "  -2.7016521e-01  1.0742588e+00 -8.3775681e-01  4.5119066e-02\n",
      "  -9.9274468e-01]]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "tf.Tensor(\n",
      "[[ 0.00227066 -0.00149452  0.01363323 -0.01107438 -0.01190203 -0.00367624\n",
      "   0.00198645  0.00481698  0.0008062 ]\n",
      " [ 0.00227066 -0.00149452  0.01363323 -0.01107438 -0.01190203 -0.00367624\n",
      "   0.00198645  0.00481698  0.0008062 ]\n",
      " [ 0.00227066 -0.00149452  0.01363323 -0.01107438 -0.01190203 -0.00367624\n",
      "   0.00198645  0.00481698  0.0008062 ]\n",
      " [ 0.00227066 -0.00149452  0.01363323 -0.01107438 -0.01190203 -0.00367624\n",
      "   0.00198645  0.00481698  0.0008062 ]\n",
      " [ 0.00227066 -0.00149452  0.01363323 -0.01107438 -0.01190203 -0.00367624\n",
      "   0.00198645  0.00481698  0.0008062 ]\n",
      " [ 0.00227066 -0.00149452  0.01363323 -0.01107438 -0.01190203 -0.00367624\n",
      "   0.00198645  0.00481698  0.0008062 ]\n",
      " [ 0.00227066 -0.00149452  0.01363323 -0.01107438 -0.01190203 -0.00367624\n",
      "   0.00198645  0.00481698  0.0008062 ]\n",
      " [ 0.00227066 -0.00149452  0.01363323 -0.01107438 -0.01190203 -0.00367624\n",
      "   0.00198645  0.00481698  0.0008062 ]], shape=(8, 9), dtype=float32)\n",
      "[[-0.6705366  -0.01296084  0.47025153  0.18793906  0.6926282  -0.162304\n",
      "   0.5254413   0.27374265 -0.57928264 -0.8472078   0.7388524  -0.20884454\n",
      "   1.3025604 ]\n",
      " [ 0.19925001  0.3935107   1.0534623  -0.14701754 -0.95176303 -2.1680007\n",
      "   0.08102694 -1.024487    2.0527396   0.36415154  0.23433745 -0.8183572\n",
      "   0.37209478]\n",
      " [-0.3806077  -1.0291396   0.69969344 -0.905635    1.2440125  -0.62966764\n",
      "   0.23482372  0.07708693 -0.41664267 -0.34595567  0.5811915  -0.5136009\n",
      "   0.75339603]\n",
      " [-0.3806077   0.3935107  -1.2252558  -0.23499475 -0.9640284   1.5639533\n",
      "  -0.57752687 -1.438615    3.0244749   0.6147776   0.07667653 -0.8691499\n",
      "   0.5636526 ]\n",
      " [-0.3806077  -2.0453186   0.14976214 -0.67919046  0.00866669 -0.3085594\n",
      "   0.77994627  1.0911815  -0.8552115   1.5337399  -1.4053361   0.4006681\n",
      "   1.698605  ]\n",
      " [ 0.19925001 -0.28394186  0.68771195  1.5672181   0.477374   -1.2809353\n",
      "   0.37086865 -0.50803775 -1.1445746  -1.9750252   2.0947363  -0.9707354\n",
      "  -0.1118262 ]\n",
      " [-0.09067884 -0.6633153   0.7236524   0.04133913  0.844713    0.02725991\n",
      "   0.50947696 -1.5120909   0.7362875  -0.4294977   0.45506275 -0.20884454\n",
      "   0.01387032]\n",
      " [-0.96046543  2.0193968  -0.81192595 -1.1222044  -1.1983857   0.0088578\n",
      "  -1.5692947  -0.06168942 -1.1633605   0.8654037  -0.5539672  -0.15805182\n",
      "  -2.6238737 ]]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "Test acc: 0.10075885057449341\n"
     ]
    }
   ],
   "source": [
    "test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "input_length = len(test_features)\n",
    "for step, input_ in test_features.groupby(np.arange(input_length) // batch_size):\n",
    "    dataFrame = pd.DataFrame(data = input_)\n",
    "    labels_ = dataFrame.guten_genre\n",
    "    features_ = dataFrame.drop('book_id', axis=1)\n",
    "    features_ = features_.drop('guten_genre', axis=1)\n",
    "    features_ = np.asarray(features_).astype(np.float32)\n",
    "    test_acc_metric(labels_, model(features_))\n",
    "    if not step % 10:\n",
    "        print(np.argmax(model(features_), axis=-1))\n",
    "    if not step % 100:\n",
    "        print(model(features_))\n",
    "        print(features_)\n",
    "print(\"Test acc: {}\".format(test_acc_metric.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0]\n",
      "tf.Tensor(\n",
      "[[ 0.04992972  0.00315021  0.03887487 -0.07362494 -0.0023321  -0.03541558\n",
      "  -0.01961228 -0.03818445 -0.05046205]\n",
      " [ 0.04992972  0.00315021  0.03887487 -0.07362494 -0.0023321  -0.03541558\n",
      "  -0.01961228 -0.03818445 -0.05046205]\n",
      " [ 0.04992972  0.00315021  0.03887487 -0.07362494 -0.0023321  -0.03541558\n",
      "  -0.01961228 -0.03818445 -0.05046205]\n",
      " [ 0.04992972  0.00315021  0.03887487 -0.07362494 -0.0023321  -0.03541558\n",
      "  -0.01961228 -0.03818445 -0.05046205]\n",
      " [ 0.04992972  0.00315021  0.03887487 -0.07362494 -0.0023321  -0.03541558\n",
      "  -0.01961228 -0.03818445 -0.05046205]\n",
      " [ 0.04992972  0.00315021  0.03887487 -0.07362494 -0.0023321  -0.03541558\n",
      "  -0.01961228 -0.03818445 -0.05046205]\n",
      " [ 0.04992972  0.00315021  0.03887487 -0.07362494 -0.0023321  -0.03541558\n",
      "  -0.01961228 -0.03818445 -0.05046205]\n",
      " [ 0.04992972  0.00315021  0.03887487 -0.07362494 -0.0023321  -0.03541558\n",
      "  -0.01961228 -0.03818445 -0.05046205]], shape=(8, 9), dtype=float32)\n",
      "[[-0.96046543  2.0193968   1.2940385  -0.53433144  0.6753901  -0.6459409\n",
      "  -1.9012266  -0.309705    0.44388926 -1.3066889   1.4325604  -0.7167718\n",
      "  -1.1907586 ]\n",
      " [-0.09067884  1.6129253  -1.1523657  -1.31026    -1.0627841   0.3884488\n",
      "  -0.7641528  -0.2625797   0.45495716 -1.0142919   0.5181271   0.3498754\n",
      "   1.7488368 ]\n",
      " [-0.6705366  -0.01296084  0.91908497 -0.43522575 -0.34665737 -1.2151823\n",
      "   0.73970246 -0.10820675  0.70621634 -1.0560628   1.180303   -0.61518633\n",
      "  -0.60298556]\n",
      " [-0.6705366  -0.01296084 -0.43888158  2.2927501   0.07046366  1.2729926\n",
      "   0.51813066 -0.93426144  0.43081856  0.40592256 -0.2701775  -0.05646638\n",
      "  -0.21300945]\n",
      " [ 0.4891789  -1.1743081  -2.2758827  -0.6661071  -1.9256159   2.1318886\n",
      "  -1.3372478  -0.9398796  -0.67192936 -0.22064263 -0.869289    1.6704862\n",
      "  -2.3233385 ]\n",
      " [ 1.0690366   0.07736617  1.0460956  -0.31513926  1.6047007   0.17742035\n",
      "   1.5604166   0.03901777  2.1144521  -1.0142919   1.2433673  -0.7675645\n",
      "  -0.5649472 ]\n",
      " [-0.96046543  0.3935107  -0.3467388   0.18808529 -0.8741084  -0.6888941\n",
      "  -0.57673675  0.12488301 -0.72652966 -1.1813759   0.8019168   0.09591179\n",
      "  -1.8863393 ]\n",
      " [ 1.0690366  -0.8259039  -1.2583818   0.0720613  -0.61411947  0.08304343\n",
      "  -1.9065992  -0.5156474  -0.0598858  -1.682628    1.2748995  -0.00567366\n",
      "   0.97755057]]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "tf.Tensor(\n",
      "[[ 0.04992972  0.00315021  0.03887487 -0.07362494 -0.0023321  -0.03541558\n",
      "  -0.01961228 -0.03818445 -0.05046205]\n",
      " [ 0.04992972  0.00315021  0.03887487 -0.07362494 -0.0023321  -0.03541558\n",
      "  -0.01961228 -0.03818445 -0.05046205]\n",
      " [ 0.04992972  0.00315021  0.03887487 -0.07362494 -0.0023321  -0.03541558\n",
      "  -0.01961228 -0.03818445 -0.05046205]\n",
      " [ 0.04992972  0.00315021  0.03887487 -0.07362494 -0.0023321  -0.03541558\n",
      "  -0.01961228 -0.03818445 -0.05046205]\n",
      " [ 0.04992972  0.00315021  0.03887487 -0.07362494 -0.0023321  -0.03541558\n",
      "  -0.01961228 -0.03818445 -0.05046205]\n",
      " [ 0.04992972  0.00315021  0.03887487 -0.07362494 -0.0023321  -0.03541558\n",
      "  -0.01961228 -0.03818445 -0.05046205]\n",
      " [ 0.04992972  0.00315021  0.03887487 -0.07362494 -0.0023321  -0.03541558\n",
      "  -0.01961228 -0.03818445 -0.05046205]\n",
      " [ 0.04992972  0.00315021  0.03887487 -0.07362494 -0.0023321  -0.03541558\n",
      "  -0.01961228 -0.03818445 -0.05046205]], shape=(8, 9), dtype=float32)\n",
      "[[-3.8060769e-01 -8.2590389e-01  5.5483562e-01  1.0878702e+00\n",
      "   4.7737008e-01  1.3128186e+00  7.8729308e-01  1.7880034e-01\n",
      "   6.5328848e-01  1.1995718e+00 -3.6477405e-01 -8.1835723e-01\n",
      "   1.7084397e+00]\n",
      " [-6.7053658e-01  2.5802019e-01  1.3277061e+00  1.3029351e+00\n",
      "   1.4059014e+00 -2.7178252e+00  9.7533959e-01  1.3049808e-03\n",
      "  -3.5359189e-01  3.2238054e-01 -6.4856368e-01  6.5463173e-01\n",
      "   7.8001760e-02]\n",
      " [-6.7053658e-01 -5.5492288e-01  2.6156253e-01  4.3106535e-01\n",
      "   4.2078492e-01  4.6613404e-01 -1.8462735e+00 -1.4665325e-01\n",
      "  -4.0333620e-01  2.8060952e-01 -2.1936407e+00  3.1942677e+00\n",
      "  -1.2037690e+00]\n",
      " [-3.8060769e-01 -2.1619660e-01 -4.7505477e-01 -1.1969556e+00\n",
      "  -1.9740883e+00  1.6247157e+00 -1.3706447e+00 -1.1367868e+00\n",
      "  -1.4714880e-01  2.2438471e+00 -1.7521901e+00  9.5911793e-02\n",
      "   2.1492901e+00]\n",
      " [-6.7053658e-01 -1.2960837e-02 -4.3888158e-01  2.2927501e+00\n",
      "   7.0463665e-02  1.2729926e+00  5.1813066e-01 -9.3426144e-01\n",
      "   4.3081856e-01  4.0592256e-01 -2.7017751e-01 -5.6466378e-02\n",
      "  -2.1300945e-01]\n",
      " [-6.7053658e-01  1.8839062e+00  2.6224613e-01 -2.1996965e-01\n",
      "  -1.0130287e+00 -6.3806641e-01 -2.6989830e-01  2.3464631e-01\n",
      "  -5.8450133e-01 -1.7887162e-01  4.8659492e-01 -6.1518633e-01\n",
      "  -2.8221276e-01]\n",
      " [ 3.3884676e+00 -5.8680302e-01 -2.0508146e+00 -2.0472552e-01\n",
      "  -1.3386798e+00  7.8360742e-01 -7.4239439e-01 -7.4429297e-01\n",
      "  -2.5103894e-01  7.1754463e-02 -1.1846108e+00  1.8228644e+00\n",
      "  -1.3998678e+00]\n",
      " [ 4.8917890e-01  3.3544332e-01 -8.3102500e-01 -6.7967427e-01\n",
      "  -1.6826691e-01  9.1712677e-01 -4.7446886e-01 -7.6768792e-01\n",
      "  -2.7016521e-01  1.0742588e+00 -8.3775681e-01  4.5119066e-02\n",
      "  -9.9274468e-01]]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "tf.Tensor(\n",
      "[[ 0.04992972  0.00315021  0.03887487 -0.07362494 -0.0023321  -0.03541558\n",
      "  -0.01961228 -0.03818445 -0.05046205]\n",
      " [ 0.04992972  0.00315021  0.03887487 -0.07362494 -0.0023321  -0.03541558\n",
      "  -0.01961228 -0.03818445 -0.05046205]\n",
      " [ 0.04992972  0.00315021  0.03887487 -0.07362494 -0.0023321  -0.03541558\n",
      "  -0.01961228 -0.03818445 -0.05046205]\n",
      " [ 0.04992972  0.00315021  0.03887487 -0.07362494 -0.0023321  -0.03541558\n",
      "  -0.01961228 -0.03818445 -0.05046205]\n",
      " [ 0.04992972  0.00315021  0.03887487 -0.07362494 -0.0023321  -0.03541558\n",
      "  -0.01961228 -0.03818445 -0.05046205]\n",
      " [ 0.04992972  0.00315021  0.03887487 -0.07362494 -0.0023321  -0.03541558\n",
      "  -0.01961228 -0.03818445 -0.05046205]\n",
      " [ 0.04992972  0.00315021  0.03887487 -0.07362494 -0.0023321  -0.03541558\n",
      "  -0.01961228 -0.03818445 -0.05046205]\n",
      " [ 0.04992972  0.00315021  0.03887487 -0.07362494 -0.0023321  -0.03541558\n",
      "  -0.01961228 -0.03818445 -0.05046205]], shape=(8, 9), dtype=float32)\n",
      "[[-0.6705366  -0.01296084  0.47025153  0.18793906  0.6926282  -0.162304\n",
      "   0.5254413   0.27374265 -0.57928264 -0.8472078   0.7388524  -0.20884454\n",
      "   1.3025604 ]\n",
      " [ 0.19925001  0.3935107   1.0534623  -0.14701754 -0.95176303 -2.1680007\n",
      "   0.08102694 -1.024487    2.0527396   0.36415154  0.23433745 -0.8183572\n",
      "   0.37209478]\n",
      " [-0.3806077  -1.0291396   0.69969344 -0.905635    1.2440125  -0.62966764\n",
      "   0.23482372  0.07708693 -0.41664267 -0.34595567  0.5811915  -0.5136009\n",
      "   0.75339603]\n",
      " [-0.3806077   0.3935107  -1.2252558  -0.23499475 -0.9640284   1.5639533\n",
      "  -0.57752687 -1.438615    3.0244749   0.6147776   0.07667653 -0.8691499\n",
      "   0.5636526 ]\n",
      " [-0.3806077  -2.0453186   0.14976214 -0.67919046  0.00866669 -0.3085594\n",
      "   0.77994627  1.0911815  -0.8552115   1.5337399  -1.4053361   0.4006681\n",
      "   1.698605  ]\n",
      " [ 0.19925001 -0.28394186  0.68771195  1.5672181   0.477374   -1.2809353\n",
      "   0.37086865 -0.50803775 -1.1445746  -1.9750252   2.0947363  -0.9707354\n",
      "  -0.1118262 ]\n",
      " [-0.09067884 -0.6633153   0.7236524   0.04133913  0.844713    0.02725991\n",
      "   0.50947696 -1.5120909   0.7362875  -0.4294977   0.45506275 -0.20884454\n",
      "   0.01387032]\n",
      " [-0.96046543  2.0193968  -0.81192595 -1.1222044  -1.1983857   0.0088578\n",
      "  -1.5692947  -0.06168942 -1.1633605   0.8654037  -0.5539672  -0.15805182\n",
      "  -2.6238737 ]]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "Test acc: 0.10919055342674255\n"
     ]
    }
   ],
   "source": [
    "test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "input_length = len(test_features)\n",
    "for step, input_ in test_features.groupby(np.arange(input_length) // batch_size):\n",
    "    dataFrame = pd.DataFrame(data = input_)\n",
    "    labels_ = dataFrame.guten_genre\n",
    "    features_ = dataFrame.drop('book_id', axis=1)\n",
    "    features_ = features_.drop('guten_genre', axis=1)\n",
    "    features_ = np.asarray(features_).astype(np.float32)\n",
    "    test_acc_metric(labels_, model2(features_))\n",
    "    if not step % 10:\n",
    "        print(np.argmax(model2(features_), axis=-1))\n",
    "    if not step % 100:\n",
    "        print(model2(features_))\n",
    "        print(features_)\n",
    "print(\"Test acc: {}\".format(test_acc_metric.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
